{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd058669-55d9-4320-9f74-a1e2f3f67517",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, unix_timestamp, hour\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9cf1880-f8c4-4109-a9cf-9e52752e1ad8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_nyc_taxi_data(df):\n",
    "    # # Step 1: Cast columns to appropriate types\n",
    "    # df = df.withColumn(\"VendorID\", col(\"VendorID\").cast(\"int\")) \\\n",
    "    #        .withColumn(\"tpep_pickup_datetime\", col(\"tpep_pickup_datetime\").cast(\"timestamp\")) \\\n",
    "    #        .withColumn(\"tpep_dropoff_datetime\", col(\"tpep_dropoff_datetime\").cast(\"timestamp\")) \\\n",
    "    #        .withColumn(\"passenger_count\", col(\"passenger_count\").cast(\"int\")) \\\n",
    "    #        .withColumn(\"trip_distance\", col(\"trip_distance\").cast(\"float\")) \\\n",
    "    #        .withColumn(\"RatecodeID\", col(\"RatecodeID\").cast(\"int\")) \\\n",
    "    #        .withColumn(\"PULocationID\", col(\"PULocationID\").cast(\"int\")) \\\n",
    "    #        .withColumn(\"DOLocationID\", col(\"DOLocationID\").cast(\"int\")) \\\n",
    "    #        .withColumn(\"payment_type\", col(\"payment_type\").cast(\"int\")) \\\n",
    "    #        .withColumn(\"fare_amount\", col(\"fare_amount\").cast(\"float\")) \\\n",
    "    #        .withColumn(\"extra\", col(\"extra\").cast(\"float\")) \\\n",
    "    #        .withColumn(\"mta_tax\", col(\"mta_tax\").cast(\"float\")) \\\n",
    "    #        .withColumn(\"tip_amount\", col(\"tip_amount\").cast(\"float\")) \\\n",
    "    #        .withColumn(\"tolls_amount\", col(\"tolls_amount\").cast(\"float\")) \\\n",
    "    #        .withColumn(\"improvement_surcharge\", col(\"improvement_surcharge\").cast(\"float\")) \\\n",
    "    #        .withColumn(\"total_amount\", col(\"total_amount\").cast(\"float\")) \\\n",
    "    #        .withColumn(\"congestion_surcharge\", col(\"congestion_surcharge\").cast(\"float\"))\n",
    "\n",
    "    # Step 2: Drop duplicates and rows with critical nulls\n",
    "    df = df.dropDuplicates()\n",
    "    df = df.dropna(subset=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"fare_amount\"])\n",
    "\n",
    "    # Step 3: Filter invalid or outlier data\n",
    "    df = df.filter((col(\"trip_distance\") > 0) & (col(\"fare_amount\") > 0))\n",
    "    df = df.filter((col(\"passenger_count\") > 0) & (col(\"passenger_count\") <= 6))\n",
    "    \n",
    "    df = df.withColumn(\"trip_time_minutes\",\n",
    "                       (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 60)\n",
    "    df = df.filter((col(\"trip_time_minutes\") > 0) & (col(\"trip_time_minutes\") < 180))\n",
    "\n",
    "    # Step 4: Standardize categorical values\n",
    "    df = df.withColumn(\"store_and_fwd_flag\",\n",
    "                       when(col(\"store_and_fwd_flag\") == \"Y\", \"Yes\").otherwise(\"No\"))\n",
    "    \n",
    "    df = df.withColumn(\"payment_type\",\n",
    "                       when(col(\"payment_type\") == 1, \"Credit Card\")\n",
    "                       .when(col(\"payment_type\") == 2, \"Cash\")\n",
    "                       .when(col(\"payment_type\") == 3, \"No Charge\")\n",
    "                       .when(col(\"payment_type\") == 4, \"Dispute\")\n",
    "                       .when(col(\"payment_type\") == 5, \"Unknown\")\n",
    "                       .otherwise(\"Other\"))\n",
    "\n",
    "    # Step 5: Add derived columns\n",
    "    df = df.withColumn(\"pickup_hour\", hour(\"tpep_pickup_datetime\")) \\\n",
    "           .withColumn(\"tip_percentage\", \n",
    "                       when(col(\"fare_amount\") > 0, (col(\"tip_amount\") / col(\"fare_amount\")) * 100).otherwise(0.0))\n",
    "           \n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c14dc301-16ed-4cd4-8b5c-fbe04f792555",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "utils_data_cleaning",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}